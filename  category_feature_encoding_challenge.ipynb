{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Categorical Feature Encoding Challenge\n",
    "#### *Binary classification, with every feature a categorical*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.api.types import CategoricalDtype \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Datasets during FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_y = train_raw['target']\n",
    "train_raw = train_raw.drop(['target'], axis = 1)\n",
    "train = train_raw.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check unique values per feature between train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"column: train unique values - test unique values\")\n",
    "for column in train.columns:\n",
    "    print(column + \": \" + str(len(train[:300000][column].unique())) + \" --> \" + str(len(train[300000:][column].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encode to binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_bins34 = {'T' : 1, 'F' : 0, 'Y' : 1, 'N' : 0}\n",
    "\n",
    "train['bin_3'] = train['bin_3'].map(mapping_bins34)\n",
    "train['bin_4'] = train['bin_4'].map(mapping_bins34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinal encoding for ordinal features with low cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['ord_1','ord_2']:\n",
    "    print(col)\n",
    "    print(train[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord1_dic = {'Novice' : 0, 'Contributor' : 1, 'Expert' : 2, 'Master' : 3, 'Grandmaster' : 4}\n",
    "ord2_dic = {'Freezing' : 0, 'Cold' : 1, 'Warm' : 2, 'Hot' : 3, 'Boiling Hot' : 4, 'Lava Hot' : 5}\n",
    "\n",
    "train['ord_1'] = train['ord_1'].map(ord1_dic)\n",
    "train['ord_2'] = train['ord_2'].map(ord2_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For mid cardinality ordinal features, sort then map to new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort ord_3 alphabetically then insert into dic then map new values\n",
    "ord3 = sorted(train['ord_3'].unique())\n",
    "ord3_dic = {}\n",
    "\n",
    "i=1\n",
    "for letter in ord3:\n",
    "    ord3_dic[letter] = i\n",
    "    i += 1\n",
    "    \n",
    "train['ord_3'] = train['ord_3'].map(ord3_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort ord_4 alphabetically then insert into dic then map new values\n",
    "ord4 = sorted(train['ord_4'].unique())\n",
    "ord4_dic = {}\n",
    "\n",
    "i=1\n",
    "for letter in ord4:\n",
    "    ord4_dic[letter] = i\n",
    "    i += 1\n",
    "    \n",
    "train['ord_4'] = train['ord_4'].map(ord4_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For high cardinality ordinal feature, add indices for 2 letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ord_5_oe_add'] = train['ord_5'].apply(lambda x:sum([(string.ascii_letters.find(letter)+1) for letter in x]))\n",
    "train = train.drop(['ord_5'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding to low cardinality nominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode nominal features\n",
    "train = pd.get_dummies(train, columns=['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4'],\\\n",
    "                          prefix=['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashing to high cardinality nominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_card_nom = ['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\n",
    "\n",
    "for col in high_card_nom:\n",
    "    train[f'hash_{col}'] = train[col].apply( lambda x: hash(str(x)) % 5000 )\n",
    "    train = train.drop([col], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test apart after feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = train[:len(train_raw)]\n",
    "test_final = train[(len(train_raw)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training Set to Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(train_final,train_y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"],'solver':\"lbfgs\"} # l1 lasso l2 ridge\n",
    "# clf=LogisticRegression()\n",
    "# clf_cv=GridSearchCV(clf,grid,cv=10)\n",
    "# clf_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"tuned hpyerparameters :(best parameters) \",clf_cv.best_params_)\n",
    "# print(\"accuracy :\",clf_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=0.1, solver=\"lbfgs\", max_iter=5000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = clf.predict_proba(test_final)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"id\": test['id'], \"target\": final_pred}).to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
